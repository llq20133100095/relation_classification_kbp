{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\n\nfrom transformers import TFAutoModel, AutoTokenizer\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import f1_score","execution_count":2,"outputs":[{"output_type":"stream","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"# 1.TPU Configs"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":3,"outputs":[{"output_type":"stream","text":"Running on TPU  grpc://10.0.0.2:8470\nREPLICAS:  8\n","name":"stdout"}]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"# 2.Configuration"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\n# Configuration\nEPOCHS = 2\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nMAX_LEN = 80\nMODEL = 'roberta-base'\n","execution_count":4,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"def read_text_data(data_file):\n    texts = []\n    labels = []\n    with open(data_file, \"r\") as f:\n        while True:\n            line = f.readline()\n            if line:\n                line = line.strip()\n                text = line.split(\"\\t\")[1]\n                label = line.split(\"\\t\")[0]\n                texts.append(text)\n                labels.append(label)\n            else:    \n                break\n    return texts, labels\n\ntrain_file = \"/kaggle/input/relation-classification-kbp/kbp_relation_classification/train_sf3.txt\"\ntest_file = \"/kaggle/input/relation-classification-kbp/kbp_relation_classification/test_sf3.txt\"\n\ntrain_texts, train_labels = read_text_data(train_file)\ntest_texts, test_labels = read_text_data(test_file)\n\n# label encode\nle = LabelEncoder()\nle.fit(train_labels)\ntrain_labels = le.transform(train_labels)\ntest_labels = le.transform(test_labels)\n\ntrain_labels = np.float32(train_labels)\ntest_labels = np.float32(test_labels)\n\nprint(len(train_texts))\nprint(len(test_labels))","execution_count":5,"outputs":[{"output_type":"stream","text":"28888\n9600\n","name":"stdout"}]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"# 3.encode token"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# First load the real tokenizer\ntokenizer = AutoTokenizer.from_pretrained(MODEL)\n\ndef regular_encode(texts, tokenizer, maxlen=512):\n    enc_di = tokenizer.batch_encode_plus(\n        texts, \n        return_attention_masks=True, \n        return_token_type_ids=True,\n        pad_to_max_length=True,\n        max_length=maxlen\n    )\n    \n    return np.array(enc_di['input_ids'], dtype=np.int32), np.array(enc_di['attention_mask'], dtype=np.int32), np.array(enc_di[\"token_type_ids\"], dtype=np.int32)\n","execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d08e6e9e8094c76841f8048904651d1"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dde5b78876e4a7cbc4138ad8bea7731"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b136e57576594567be9ec9bd093325a2"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"# 4.Build model"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"def F1_scores(labels, predict):\n    predict = np.argmax(predict, axis=1)\n    result = f1_score(labels, predict, average=\"macro\")\n    return result\n    \n    \ndef build_model(transformer, max_len=512):\n    \"\"\"\n    https://www.kaggle.com/xhlulu/jigsaw-tpu-distilbert-with-huggingface-and-keras\n    \"\"\"\n    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n    sequence_output = transformer((input_word_ids, input_mask, segment_ids))[0]\n    gp = tf.keras.layers.GlobalMaxPooling1D()(sequence_output)\n    ap = tf.keras.layers.GlobalAveragePooling1D()(sequence_output)\n    stack = tf.keras.layers.concatenate([gp, ap], axis=1)\n    # stack = tf.keras.layers.Dropout(0.2)(stack)\n    out = Dense(40, activation='softmax')(stack)\n    \n    \n    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n    model.compile(Adam(lr=1e-6), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n    \n    return model","execution_count":7,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"# 5. Train"},{"metadata":{"pycharm":{"name":"#%% \n"},"trusted":true},"cell_type":"code","source":"x_train = regular_encode(train_texts, tokenizer, maxlen=MAX_LEN)\nx_test = regular_encode(test_texts, tokenizer, maxlen=MAX_LEN)\n\ntrain_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((x_train, train_labels))\n    .repeat()\n    .shuffle(50)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((x_test, test_labels))\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)","execution_count":8,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"%%time\nwith strategy.scope():\n    transformer_layer = TFAutoModel.from_pretrained(MODEL)\n    model = build_model(transformer_layer, max_len=MAX_LEN)\n    \nmodel.summary()","execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=657434796.0, style=ProgressStyle(descri…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1492b42fe9454bbc82f6f9aa4c752257"}},"metadata":{}},{"output_type":"stream","text":"\nModel: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_word_ids (InputLayer)     [(None, 80)]         0                                            \n__________________________________________________________________________________________________\ninput_mask (InputLayer)         [(None, 80)]         0                                            \n__________________________________________________________________________________________________\nsegment_ids (InputLayer)        [(None, 80)]         0                                            \n__________________________________________________________________________________________________\ntf_roberta_model (TFRobertaMode ((None, 80, 768), (N 124645632   input_word_ids[0][0]             \n                                                                 input_mask[0][0]                 \n                                                                 segment_ids[0][0]                \n__________________________________________________________________________________________________\nglobal_max_pooling1d (GlobalMax (None, 768)          0           tf_roberta_model[0][0]           \n__________________________________________________________________________________________________\nglobal_average_pooling1d (Globa (None, 768)          0           tf_roberta_model[0][0]           \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 1536)         0           global_max_pooling1d[0][0]       \n                                                                 global_average_pooling1d[0][0]   \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 40)           61480       concatenate[0][0]                \n==================================================================================================\nTotal params: 124,707,112\nTrainable params: 124,707,112\nNon-trainable params: 0\n__________________________________________________________________________________________________\nCPU times: user 31.9 s, sys: 8.95 s, total: 40.8 s\nWall time: 41.5 s\n","name":"stdout"}]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"n_steps = len(train_texts) // BATCH_SIZE\ntrain_history = model.fit(\n    train_dataset,\n    steps_per_epoch=n_steps,\n    validation_data=test_dataset,\n    epochs=70,\n    shuffle=True,\n)\n\ntest_predicts = model.predict(x_test)\nresult = F1_scores(test_labels, test_predicts)\nprint(result)","execution_count":10,"outputs":[{"output_type":"stream","text":"Epoch 1/60\n225/225 [==============================] - 35s 154ms/step - accuracy: 0.0210 - loss: 4.2287 - val_accuracy: 0.1054 - val_loss: 3.5503\nEpoch 2/60\n225/225 [==============================] - 24s 106ms/step - accuracy: 0.1088 - loss: 3.6448 - val_accuracy: 0.1116 - val_loss: 3.3818\nEpoch 3/60\n225/225 [==============================] - 24s 105ms/step - accuracy: 0.1233 - loss: 3.4815 - val_accuracy: 0.1115 - val_loss: 3.3182\nEpoch 4/60\n225/225 [==============================] - 24s 107ms/step - accuracy: 0.1246 - loss: 3.4089 - val_accuracy: 0.1116 - val_loss: 3.2709\nEpoch 5/60\n225/225 [==============================] - 24s 107ms/step - accuracy: 0.1168 - loss: 3.3687 - val_accuracy: 0.1192 - val_loss: 3.2232\nEpoch 6/60\n225/225 [==============================] - 24s 105ms/step - accuracy: 0.1160 - loss: 3.3129 - val_accuracy: 0.1345 - val_loss: 3.1919\nEpoch 7/60\n225/225 [==============================] - 24s 106ms/step - accuracy: 0.1282 - loss: 3.2601 - val_accuracy: 0.1380 - val_loss: 3.1549\nEpoch 8/60\n225/225 [==============================] - 24s 107ms/step - accuracy: 0.1371 - loss: 3.2120 - val_accuracy: 0.1556 - val_loss: 3.0955\nEpoch 9/60\n225/225 [==============================] - 24s 106ms/step - accuracy: 0.1500 - loss: 3.1465 - val_accuracy: 0.1945 - val_loss: 3.0068\nEpoch 10/60\n225/225 [==============================] - 24s 107ms/step - accuracy: 0.1780 - loss: 3.0600 - val_accuracy: 0.2146 - val_loss: 2.9037\nEpoch 11/60\n225/225 [==============================] - 24s 107ms/step - accuracy: 0.2075 - loss: 2.9534 - val_accuracy: 0.2239 - val_loss: 2.7897\nEpoch 12/60\n225/225 [==============================] - 24s 108ms/step - accuracy: 0.2272 - loss: 2.8331 - val_accuracy: 0.2248 - val_loss: 2.6711\nEpoch 13/60\n225/225 [==============================] - 24s 108ms/step - accuracy: 0.2688 - loss: 2.6774 - val_accuracy: 0.2402 - val_loss: 2.5369\nEpoch 14/60\n225/225 [==============================] - 24s 107ms/step - accuracy: 0.2990 - loss: 2.5272 - val_accuracy: 0.2949 - val_loss: 2.3604\nEpoch 15/60\n225/225 [==============================] - 24s 105ms/step - accuracy: 0.3321 - loss: 2.3675 - val_accuracy: 0.3257 - val_loss: 2.2257\nEpoch 16/60\n225/225 [==============================] - 24s 105ms/step - accuracy: 0.3870 - loss: 2.1798 - val_accuracy: 0.3354 - val_loss: 2.1927\nEpoch 17/60\n225/225 [==============================] - 24s 106ms/step - accuracy: 0.4361 - loss: 2.0463 - val_accuracy: 0.3894 - val_loss: 2.0297\nEpoch 18/60\n225/225 [==============================] - 24s 107ms/step - accuracy: 0.4781 - loss: 1.9177 - val_accuracy: 0.4626 - val_loss: 1.8119\nEpoch 19/60\n225/225 [==============================] - 24s 108ms/step - accuracy: 0.5155 - loss: 1.7770 - val_accuracy: 0.4943 - val_loss: 1.7205\nEpoch 20/60\n225/225 [==============================] - 24s 106ms/step - accuracy: 0.5493 - loss: 1.6590 - val_accuracy: 0.5264 - val_loss: 1.6450\nEpoch 21/60\n225/225 [==============================] - 24s 106ms/step - accuracy: 0.5831 - loss: 1.5498 - val_accuracy: 0.5606 - val_loss: 1.5592\nEpoch 22/60\n225/225 [==============================] - 24s 105ms/step - accuracy: 0.6080 - loss: 1.4635 - val_accuracy: 0.5833 - val_loss: 1.4574\nEpoch 23/60\n225/225 [==============================] - 24s 106ms/step - accuracy: 0.6226 - loss: 1.3956 - val_accuracy: 0.6084 - val_loss: 1.3556\nEpoch 24/60\n225/225 [==============================] - 25s 112ms/step - accuracy: 0.6357 - loss: 1.3367 - val_accuracy: 0.6310 - val_loss: 1.2675\nEpoch 25/60\n225/225 [==============================] - 24s 107ms/step - accuracy: 0.6470 - loss: 1.2853 - val_accuracy: 0.6531 - val_loss: 1.1948\nEpoch 26/60\n225/225 [==============================] - 24s 109ms/step - accuracy: 0.6549 - loss: 1.2440 - val_accuracy: 0.6665 - val_loss: 1.1324\nEpoch 27/60\n225/225 [==============================] - 24s 106ms/step - accuracy: 0.6621 - loss: 1.2061 - val_accuracy: 0.6727 - val_loss: 1.0912\nEpoch 28/60\n225/225 [==============================] - 24s 105ms/step - accuracy: 0.6685 - loss: 1.1693 - val_accuracy: 0.6797 - val_loss: 1.0588\nEpoch 29/60\n225/225 [==============================] - 24s 107ms/step - accuracy: 0.6722 - loss: 1.1397 - val_accuracy: 0.6829 - val_loss: 1.0348\nEpoch 30/60\n225/225 [==============================] - 24s 107ms/step - accuracy: 0.6755 - loss: 1.1191 - val_accuracy: 0.6879 - val_loss: 1.0106\nEpoch 31/60\n225/225 [==============================] - 24s 106ms/step - accuracy: 0.6785 - loss: 1.0902 - val_accuracy: 0.6956 - val_loss: 0.9878\nEpoch 32/60\n225/225 [==============================] - 24s 107ms/step - accuracy: 0.6789 - loss: 1.0770 - val_accuracy: 0.7058 - val_loss: 0.9619\nEpoch 33/60\n225/225 [==============================] - 24s 108ms/step - accuracy: 0.6885 - loss: 1.0502 - val_accuracy: 0.7159 - val_loss: 0.9279\nEpoch 34/60\n225/225 [==============================] - 24s 106ms/step - accuracy: 0.6961 - loss: 1.0200 - val_accuracy: 0.7267 - val_loss: 0.8982\nEpoch 35/60\n225/225 [==============================] - 24s 107ms/step - accuracy: 0.7031 - loss: 0.9891 - val_accuracy: 0.7333 - val_loss: 0.8727\nEpoch 36/60\n225/225 [==============================] - 24s 107ms/step - accuracy: 0.7099 - loss: 0.9659 - val_accuracy: 0.7421 - val_loss: 0.8480\nEpoch 37/60\n225/225 [==============================] - 24s 106ms/step - accuracy: 0.7146 - loss: 0.9418 - val_accuracy: 0.7461 - val_loss: 0.8318\nEpoch 38/60\n225/225 [==============================] - 24s 106ms/step - accuracy: 0.7204 - loss: 0.9223 - val_accuracy: 0.7508 - val_loss: 0.8116\nEpoch 39/60\n225/225 [==============================] - 24s 108ms/step - accuracy: 0.7268 - loss: 0.8993 - val_accuracy: 0.7548 - val_loss: 0.7961\nEpoch 40/60\n225/225 [==============================] - 24s 107ms/step - accuracy: 0.7277 - loss: 0.8829 - val_accuracy: 0.7571 - val_loss: 0.7837\nEpoch 41/60\n225/225 [==============================] - 24s 107ms/step - accuracy: 0.7335 - loss: 0.8652 - val_accuracy: 0.7583 - val_loss: 0.7724\nEpoch 42/60\n225/225 [==============================] - 24s 106ms/step - accuracy: 0.7371 - loss: 0.8478 - val_accuracy: 0.7615 - val_loss: 0.7602\nEpoch 43/60\n225/225 [==============================] - 24s 107ms/step - accuracy: 0.7378 - loss: 0.8385 - val_accuracy: 0.7635 - val_loss: 0.7508\nEpoch 44/60\n225/225 [==============================] - 23s 104ms/step - accuracy: 0.7431 - loss: 0.8220 - val_accuracy: 0.7645 - val_loss: 0.7432\nEpoch 45/60\n225/225 [==============================] - 24s 106ms/step - accuracy: 0.7440 - loss: 0.8131 - val_accuracy: 0.7648 - val_loss: 0.7366\nEpoch 46/60\n225/225 [==============================] - 25s 109ms/step - accuracy: 0.7475 - loss: 0.7992 - val_accuracy: 0.7670 - val_loss: 0.7302\nEpoch 47/60\n225/225 [==============================] - 24s 108ms/step - accuracy: 0.7491 - loss: 0.7885 - val_accuracy: 0.7679 - val_loss: 0.7250\nEpoch 48/60\n225/225 [==============================] - 24s 108ms/step - accuracy: 0.7542 - loss: 0.7756 - val_accuracy: 0.7691 - val_loss: 0.7185\nEpoch 49/60\n225/225 [==============================] - 24s 107ms/step - accuracy: 0.7567 - loss: 0.7665 - val_accuracy: 0.7705 - val_loss: 0.7122\nEpoch 50/60\n225/225 [==============================] - 24s 107ms/step - accuracy: 0.7576 - loss: 0.7558 - val_accuracy: 0.7730 - val_loss: 0.7046\nEpoch 51/60\n225/225 [==============================] - 24s 108ms/step - accuracy: 0.7595 - loss: 0.7453 - val_accuracy: 0.7733 - val_loss: 0.7005\nEpoch 52/60\n225/225 [==============================] - 24s 107ms/step - accuracy: 0.7620 - loss: 0.7327 - val_accuracy: 0.7741 - val_loss: 0.6956\nEpoch 53/60\n225/225 [==============================] - 24s 107ms/step - accuracy: 0.7642 - loss: 0.7288 - val_accuracy: 0.7758 - val_loss: 0.6908\nEpoch 54/60\n225/225 [==============================] - 24s 107ms/step - accuracy: 0.7673 - loss: 0.7143 - val_accuracy: 0.7759 - val_loss: 0.6859\nEpoch 55/60\n225/225 [==============================] - 24s 107ms/step - accuracy: 0.7703 - loss: 0.7076 - val_accuracy: 0.7765 - val_loss: 0.6840\nEpoch 56/60\n225/225 [==============================] - 24s 106ms/step - accuracy: 0.7716 - loss: 0.7019 - val_accuracy: 0.7772 - val_loss: 0.6789\nEpoch 57/60\n","name":"stdout"},{"output_type":"stream","text":"225/225 [==============================] - 24s 106ms/step - accuracy: 0.7722 - loss: 0.6976 - val_accuracy: 0.7781 - val_loss: 0.6741\nEpoch 58/60\n225/225 [==============================] - 24s 107ms/step - accuracy: 0.7751 - loss: 0.6906 - val_accuracy: 0.7802 - val_loss: 0.6690\nEpoch 59/60\n225/225 [==============================] - 24s 107ms/step - accuracy: 0.7780 - loss: 0.6777 - val_accuracy: 0.7836 - val_loss: 0.6636\nEpoch 60/60\n225/225 [==============================] - 24s 107ms/step - accuracy: 0.7771 - loss: 0.6744 - val_accuracy: 0.7836 - val_loss: 0.6598\n0.7272447435530616\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}